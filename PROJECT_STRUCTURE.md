# SimpleNeural-DSL Project Structure

## ğŸ“‚ Struktur Direktori

```
automata/
â”œâ”€â”€ README.md                    # Dokumentasi utama
â”œâ”€â”€ QUICKSTART.md               # Panduan cepat
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ test_compiler.py            # Test suite
â”‚
â”œâ”€â”€ simpleneural/               # ğŸ”§ Package Utama
â”‚   â”œâ”€â”€ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ __main__.py            # Entry point (python -m)
â”‚   â”œâ”€â”€ lexer.py               # Lexical Analyzer (650+ lines)
â”‚   â”œâ”€â”€ parser.py              # Syntax Parser (500+ lines)
â”‚   â”œâ”€â”€ semantic.py            # Semantic Analyzer (400+ lines)
â”‚   â”œâ”€â”€ codegen.py             # Code Generator (500+ lines)
â”‚   â”œâ”€â”€ compiler.py            # Main Compiler (250+ lines)
â”‚   â””â”€â”€ cli.py                 # CLI Interface (250+ lines)
â”‚
â”œâ”€â”€ examples/                   # ğŸ“ Contoh File DSL
â”‚   â”œâ”€â”€ minimal.sndsl          # Contoh minimal
â”‚   â”œâ”€â”€ housing_regression.sndsl    # Prediksi harga rumah
â”‚   â”œâ”€â”€ iris_classification.sndsl   # Klasifikasi Iris
â”‚   â”œâ”€â”€ deep_network.sndsl     # Deep neural network
â”‚   â”œâ”€â”€ lstm_timeseries.sndsl  # Time series LSTM
â”‚   â””â”€â”€ error_test.sndsl       # Test error detection
â”‚
â””â”€â”€ docs/                       # ğŸ“š Dokumentasi Lengkap
    â”œâ”€â”€ README.md              # Index dokumentasi
    â”œâ”€â”€ 01-pendahuluan.md      # Latar belakang & tujuan
    â”œâ”€â”€ 02-use-case.md         # Use case analysis
    â”œâ”€â”€ 03-arsitektur.md       # Arsitektur sistem
    â”œâ”€â”€ 04-grammar-token.md    # Spesifikasi grammar
    â”œâ”€â”€ 05-implementasi.md     # Detail implementasi
    â””â”€â”€ 06-testing-examples.md # Testing & examples
```

## ğŸ¯ Komponen Utama

### 1. Lexer (lexer.py)
- **Fungsi**: Tokenization - mengubah source code menjadi token stream
- **Teknik**: Finite Automata berbasis Regular Expression
- **Token Types**: 30+ jenis token (keywords, literals, punctuation)
- **Error Handling**: LexerError dengan line & column information

**Fitur:**
- Pattern matching menggunakan compiled regex
- Support untuk comments (#)
- Whitespace handling
- String, integer, float, boolean literals
- Tuple literals untuk kernel_size dan pool_size

### 2. Parser (parser.py)
- **Fungsi**: Syntax Analysis - membuat Abstract Syntax Tree (AST)
- **Teknik**: Recursive Descent Parsing (LL(1))
- **AST Nodes**: 7 jenis node (Program, Dataset, Model, Layer, dll)
- **Error Handling**: ParseError dengan informasi posisi

**Fitur:**
- Context-Free Grammar implementation
- Hierarchical AST structure
- Parameter parsing dan validation
- Newline handling
- Pretty-print AST untuk debugging

### 3. Semantic Analyzer (semantic.py)
- **Fungsi**: Semantic validation & type checking
- **Teknik**: Symbol Table, Type System
- **Validasi**: Parameter ranges, types, business rules
- **Error & Warnings**: Detailed error messages dengan suggestions

**Fitur:**
- Valid activation function checking
- Valid optimizer checking
- Parameter range validation (learning rate, dropout rate, etc.)
- Required parameter checking
- Model structure validation
- Symbol table untuk duplicate checking

### 4. Code Generator (codegen.py)
- **Fungsi**: Generate Python code dari validated AST
- **Teknik**: Template-based code generation
- **Output**: Clean, PEP8-compliant Python code
- **Framework**: TensorFlow 2.x / Keras

**Fitur:**
- Modular code generation (imports, data loading, model, training)
- Support untuk semua layer types
- Optimizer configuration
- Training dengan callbacks (EarlyStopping, ReduceLROnPlateau)
- Evaluation metrics (MSE, MAE, RÂ²)
- Model saving

### 5. Compiler (compiler.py)
- **Fungsi**: Orchestrate semua komponen
- **Pipeline**: Lexer â†’ Parser â†’ Semantic â†’ CodeGen
- **Error Handling**: Comprehensive error reporting
- **Modes**: Compile, validate, compile-and-run

**Fitur:**
- Multi-stage compilation
- Verbose mode untuk debugging
- Error collection dan reporting
- Warning system
- File I/O handling

### 6. CLI (cli.py)
- **Fungsi**: Command-line interface
- **Commands**: compile, validate, run, tokenize, ast
- **Features**: Argparse-based, help messages, exit codes

## ğŸš€ Cara Penggunaan

### Installation
```bash
pip install -r requirements.txt
pip install -e .
```

### Basic Usage
```bash
# Validate
simpleneural validate examples/minimal.sndsl

# Compile
simpleneural compile examples/housing_regression.sndsl -o model.py

# Run
simpleneural run examples/iris_classification.sndsl

# Debug
simpleneural tokenize examples/minimal.sndsl
simpleneural ast examples/minimal.sndsl
```

### Python API
```python
from simpleneural import Compiler

# Compile from file
compiler = Compiler(verbose=True)
compiler.compile_file('model.sndsl', 'output.py')

# Compile from string
result = compiler.compile_string(dsl_code, 'source.sndsl')
if result['success']:
    print(result['code'])
```

## ğŸ“Š Statistics

### Code Metrics
- **Total Lines of Code**: ~2,500+
- **Python Modules**: 7
- **DSL Examples**: 6
- **Documentation**: 6 markdown files
- **Test Coverage**: 6 comprehensive tests

### Supported Features
- **Layer Types**: 8 (Dense, Conv2D, Dropout, Flatten, LSTM, GRU, BatchNorm, MaxPool2D)
- **Activations**: 9 (relu, sigmoid, tanh, softmax, linear, selu, elu, swish, gelu)
- **Optimizers**: 6 (adam, sgd, rmsprop, adagrad, adamw, nadam)
- **Parameters**: 15+ configurable parameters

## ğŸ§ª Testing

### Test Suite (test_compiler.py)
```bash
python test_compiler.py
```

Tests:
1. âœ… Lexer - Tokenization
2. âœ… Parser - Syntax Analysis
3. âœ… Semantic Analyzer - Validation
4. âœ… Code Generator - Python Output
5. âœ… Full Compiler - End-to-End
6. âœ… Error Detection - Error Handling

### Example Validation
```bash
# All examples
for file in examples/*.sndsl; do
    simpleneural validate "$file"
done
```

## ğŸ“ Konsep Automata

### Implementasi Teori
| Komponen | Konsep | Implementasi |
|----------|--------|--------------|
| **Lexer** | DFA/NFA | Token pattern matching |
| **Lexer** | Regular Expression | Token definition |
| **Parser** | CFG (Context-Free Grammar) | Grammar rules |
| **Parser** | Recursive Descent | LL(1) parsing |
| **Semantic** | Symbol Table | Scope tracking |
| **Semantic** | Type System | Type checking |
| **CodeGen** | Template-based | AST transformation |

### Grammar (Simplified BNF)
```bnf
Program    ::= Dataset? Model+
Dataset    ::= DATASET load STRING TARGET STRING
Model      ::= MODEL STRING { Layer+ Optimizer? TrainConfig? }
Layer      ::= LAYER LayerType Parameters*
Optimizer  ::= OPTIMIZER STRING Parameters+
TrainConfig ::= TRAIN Parameters+
Parameters ::= IDENTIFIER : Value
Value      ::= STRING | INTEGER | FLOAT | BOOLEAN | TUPLE
```

## ğŸ“ DSL Syntax

### Minimal Example
```plaintext
DATASET load "data.csv" TARGET "y"

MODEL "SimpleModel" {
    LAYER DENSE units: 32 activation: "relu"
    LAYER DENSE units: 1 activation: "linear"
    
    OPTIMIZER "adam" lr: 0.01
    TRAIN epochs: 50 batch_size: 32 validation_split: 0.2
}
```

### Advanced Example
```plaintext
DATASET load "complex_data.csv" TARGET "outcome"

MODEL "DeepNetwork" {
    LAYER DENSE units: 256 activation: "relu"
    LAYER BATCHNORM
    LAYER DROPOUT rate: 0.4
    
    LAYER LSTM units: 128 return_sequences: true
    LAYER DROPOUT rate: 0.3
    
    LAYER DENSE units: 64 activation: "relu"
    LAYER DENSE units: 1 activation: "sigmoid"
    
    OPTIMIZER "adam" lr: 0.0005
    TRAIN epochs: 150 batch_size: 64 validation_split: 0.25
}
```

## ğŸ”§ Development

### Adding New Features

#### 1. New Layer Type
1. Add token in `lexer.py`: `KEYWORD_NEWLAYER`
2. Add pattern in `TOKEN_PATTERNS`
3. Update parser in `parser.py`: layer type checking
4. Add validation in `semantic.py`: `LAYER_PARAMS`
5. Add code generation in `codegen.py`: `generate_layer()`

#### 2. New Optimizer
1. Add to `VALID_OPTIMIZERS` in `semantic.py`
2. Add case in `generate_optimizer()` in `codegen.py`

#### 3. New Activation
1. Add to `VALID_ACTIVATIONS` in `semantic.py`

## ğŸ“š Documentation

### Main Documentation
- [README.md](README.md) - Main documentation
- [QUICKSTART.md](QUICKSTART.md) - Quick start guide

### Detailed Documentation (docs/)
1. **Pendahuluan**: Background, objectives, requirements
2. **Use Case**: Diagrams, specifications, user stories
3. **Arsitektur**: ERD, system architecture, class diagrams
4. **Grammar**: Token specification, CFG, semantic rules
5. **Implementasi**: Code generation, pseudocode, CLI
6. **Testing**: Test plan, examples, deployment

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create feature branch
3. Add tests for new features
4. Update documentation
5. Submit pull request

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file

## ğŸ‘¥ Authors

SimpleNeural Team - Tugas Teori Automata & Bahasa Formal

## ğŸ™ Acknowledgments

- TensorFlow/Keras team
- Python community
- Automata theory course materials

---

**SimpleNeural-DSL** - Making Machine Learning Configuration Simple! ğŸš€
